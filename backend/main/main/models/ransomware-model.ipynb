{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e21829fe",
   "metadata": {},
   "source": [
    "## 필요한 모듈 및 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bea08b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _pywrap_checkpoint_reader: 애플리케이션 제어 정책에서 이 파일을 차단했습니다.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n",
      "File \u001b[1;32mc:\\Users\\sea45\\OneDrive\\Desktop\\Ransomware-ai\\Ransomware-Behavior-Analytics\\venv\\lib\\site-packages\\tensorflow\\__init__.py:37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sea45\\OneDrive\\Desktop\\Ransomware-ai\\Ransomware-Behavior-Analytics\\venv\\lib\\site-packages\\tensorflow\\python\\__init__.py:42\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# from tensorflow.python import keras\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sea45\\OneDrive\\Desktop\\Ransomware-ai\\Ransomware-Behavior-Analytics\\venv\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"`tf.data.Dataset` API for input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mSee [Importing Data](https://tensorflow.org/guide/data) for an overview.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n",
      "File \u001b[1;32mc:\\Users\\sea45\\OneDrive\\Desktop\\Ransomware-ai\\Ransomware-Behavior-Analytics\\venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:96\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Experimental API for building input pipelines.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains experimental `Dataset` sources and transformations that can\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m@@UNKNOWN_CARDINALITY\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m service\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dense_to_ragged_batch\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatching\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dense_to_sparse_batch\n",
      "File \u001b[1;32mc:\\Users\\sea45\\OneDrive\\Desktop\\Ransomware-ai\\Ransomware-Behavior-Analytics\\venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:419\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"API for using the tf.data service.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mThis module contains:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03m  job of ParameterServerStrategy).\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_dataset_id\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_service_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m register_dataset\n",
      "File \u001b[1;32mc:\\Users\\sea45\\OneDrive\\Desktop\\Ransomware-ai\\Ransomware-Behavior-Analytics\\venv\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_server_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mservice\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataset_ops\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m options \u001b[38;5;28;01mas\u001b[39;00m options_lib\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured_function\n",
      "File \u001b[1;32mc:\\Users\\sea45\\OneDrive\\Desktop\\Ransomware-ai\\Ransomware-Behavior-Analytics\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m graph_pb2\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m iterator_ops\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m options \u001b[38;5;28;01mas\u001b[39;00m options_lib\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m structured_function\n",
      "File \u001b[1;32mc:\\Users\\sea45\\OneDrive\\Desktop\\Ransomware-ai\\Ransomware-Behavior-Analytics\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_dataset_ops\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrackable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m base \u001b[38;5;28;01mas\u001b[39;00m trackable\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaver\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseSaverBuilder\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pywrap_utils\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deprecation\n",
      "File \u001b[1;32mc:\\Users\\sea45\\OneDrive\\Desktop\\Ransomware-ai\\Ransomware-Behavior-Analytics\\venv\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:50\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpywrap_saved_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrackable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m base \u001b[38;5;28;01mas\u001b[39;00m trackable\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m py_checkpoint_reader\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m training_util\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m saveable_object\n",
      "File \u001b[1;32mc:\\Users\\sea45\\OneDrive\\Desktop\\Ransomware-ai\\Ransomware-Behavior-Analytics\\venv\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m errors_impl\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_pywrap_checkpoint_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CheckpointReader\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21merror_translator\u001b[39m(e):\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _pywrap_checkpoint_reader: 애플리케이션 제어 정책에서 이 파일을 차단했습니다."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)      # numpy의 전역 난수 시드를 설정\n",
    "tf.random.set_seed(SEED)  # Tensorflow의 전역 난수 시드를 정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a7b0ce",
   "metadata": {},
   "source": [
    "### Synthetic Ransomware Dataset 생성  \n",
    "실제 악성 코드 바이너리를 다루지 않고, 행위 피처(behavior features)만 통계적으로 모사한 Synthetic 데이터셋 생성.  \n",
    "--> 실제 환경에서는 EDR/로그 시스템에서 추출되는 Feature Table에 해당하는 개념."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4df515",
   "metadata": {},
   "source": [
    "### Feature 설계 개요\n",
    "- encryption_count : 암호화된 파일 개수\n",
    "  - Encryptor 계열 랜섬웨어는 파일 암호화가 핵심 동작이기 때문에 수치가 매우 높음.\n",
    "  - 정상 프로세스트에는 급격히 증가하는 암호화 시도 횟수는 없음\n",
    "- file_write_rate : 초당 파일 쓰기 속도\n",
    "  - 암호화 과정에서 파일 overwrite, remane등이 폭증\n",
    "  - Encryptor, Worm-propagating, Human-operated 계열에서 증가\n",
    "- registry_modifications : 레지스트리 변경 횟수\n",
    "  - 지속성(Persistence) 확보를 위해 Run Key 수정, UAC 우회, 서비스 등록 등\n",
    "- network_connections\n",
    "  - 네트워크 이벤트 수\n",
    "  - 예 : C2 서버 연결, lateral movement 시도, 네트워크 스캔 등\n",
    "  - Worm, Exploit 기반 랜섬웨어는 내부 네트워크로 퍼지기 때문에 값이 높음\n",
    "- process_tree_depth : 프로세스 트리 깊이\n",
    "  - 공격 도구가 여러 단계를 거쳐 실행되면 깊이가 늘어남\n",
    "  - Human-operated의 경우 공격자가 다양한 실행 단계를 밟기 때문에 값이 높음\n",
    "- bruteforce_attempts : 비밀번호 추측 공격(RDP 등) 횟수(브루트포스 시도 횟수)\n",
    "  - RDP brute-force 공격 기반 랜섬웨어 (예: Dharma, SamSam)는 값이 매우 높음\n",
    "  - Encryptor/Locker 계열은 brue-force 단계가 거의 없음\n",
    "- usb_access_count : USB 접근 횟수\n",
    "  - USB 매체를 통해 전파되는 유형은 값이 매우 높음\n",
    "  - 기업 내부 오프라인 확산을 노리는 공격에서 두드러짐\n",
    "- cloud_api_access : 클라우드 API 호출 횟수\n",
    "  - 최근 랜섬웨어는 OneDrive/Google Drive 등 클라우드 스토리치 파일도 암호화함\n",
    "  - Cloud-targeted 랜섬웨어는 높은 수치\n",
    "- phishing_indicator : 피싱 기반의 초기 유입 여부(0~1 사이 확률)\n",
    "  - 이메일 첨부파일/링크 기반 공격은 이 값이 높도록 설정함\n",
    "  - Phshing-based Ransom 유형은 거의 1에 가까움\n",
    "- exploit_indicator : 취약점(Exploit) 기반 침입 여부(0~1 사이 확률)\n",
    "  - EternalBlue 같은 익스플로잇 활용 공격은 값이 높음\n",
    "  - Exploit-based Ransom 유형에서 특히 높게 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9099b95c",
   "metadata": {},
   "source": [
    "### 1. 랜섬웨어 Synthetic 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# 클래스 ID를 랜섬웨어 유형 이름으로 매핑하는 딕셔너리 정의\n",
    "# ==================================================\n",
    "class_names = {\n",
    "    0: \"Encryptor\",\n",
    "    1: \"Locker\",\n",
    "    2: \"Wiper\",\n",
    "    3: \"Worm-propagating Ransom\",\n",
    "    4: \"Human-operated Ransom\",\n",
    "    5: \"Phishing-based Ransom\",\n",
    "    6: \"RDP Brute-force based\",\n",
    "    7: \"Exploit-based Ransom\",\n",
    "    8: \"USB/Removable-media Ransom\",\n",
    "    9: \"Cloud/SaaS-targeted Ransom\",\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 각 랜섬웨어 유형별 평균적인 행위 특징(Behavior Feature 값)을 정의\n",
    "# 각 class_id 별로 해당 행동 패턴의 특징값을 params에 넣은 매칭 구조\n",
    "# ============================================================\n",
    "params = {\n",
    "    0: dict(enc=800,  fw=300,  reg=80,  net=40,  depth=7,  brute=5,  usb=5,  cloud=5,  ph=0.1, ex=0.2),\n",
    "    1: dict(enc=5,    fw=20,   reg=10,  net=10,  depth=4,  brute=2,  usb=3,  cloud=3,  ph=0.0, ex=0.1),\n",
    "    2: dict(enc=10,   fw=150,  reg=30,  net=20,  depth=5,  brute=3,  usb=4,  cloud=4,  ph=0.0, ex=0.2),\n",
    "    3: dict(enc=400,  fw=250,  reg=70,  net=80,  depth=8,  brute=6,  usb=6,  cloud=6,  ph=0.1, ex=0.3),\n",
    "    4: dict(enc=900,  fw=350,  reg=120, net=60,  depth=9,  brute=8,  usb=5,  cloud=5,  ph=0.2, ex=0.3),\n",
    "    5: dict(enc=300,  fw=150,  reg=40,  net=30,  depth=5,  brute=3,  usb=3,  cloud=3,  ph=0.9, ex=0.2),\n",
    "    6: dict(enc=200,  fw=180,  reg=60,  net=50,  depth=6,  brute=20, usb=4,  cloud=4,  ph=0.1, ex=0.2),\n",
    "    7: dict(enc=500,  fw=220,  reg=70,  net=70,  depth=7,  brute=6,  usb=4,  cloud=4,  ph=0.2, ex=0.9),\n",
    "    8: dict(enc=250,  fw=200,  reg=50,  net=25,  depth=5,  brute=4,  usb=30, cloud=3,  ph=0.1, ex=0.2),\n",
    "    9: dict(enc=350,  fw=220,  reg=60,  net=35,  depth=6,  brute=4,  usb=4,  cloud=25, ph=0.2, ex=0.3),\n",
    "}\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 전체 데이터에서 각 클래스가 등장한 비율을 정의\n",
    "# encryptor는 전체에서 15%가 되도록 샘플링\n",
    "# 0: \"Encryptor\",\n",
    "# 1: \"Locker\",\n",
    "# 2: \"Wiper\",\n",
    "# 3: \"Worm-propagating Ransom\",\n",
    "# 4: \"Human-operated Ransom\",\n",
    "# 5: \"Phishing-based Ransom\",\n",
    "# 6: \"RDP Brute-force based\",\n",
    "# 7: \"Exploit-based Ransom\",\n",
    "# 8: \"USB/Removable-media Ransom\",\n",
    "# 9: \"Cloud/SaaS-targeted Ransom\",\n",
    "# =========================================\n",
    "class_probs = [0.15, 0.05, 0.05, 0.10, 0.15, 0.10, 0.10, 0.10, 0.10, 0.10]\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Synthetic Ransomware Dataset 생성 함수 정의\n",
    "# ==========================================\n",
    "def generate_synthetic_ransomware(n_samples: int = 10000, seed: int = 42) -> pd.DataFrame:\n",
    "    \n",
    "    np.random.seed(seed) # numpy 난수 시드를 고정\n",
    "    \n",
    "    rows = []            # 각 샘플 정보를 저장할 리스트를 초기화\n",
    "\n",
    "    # for문으로 지정된 샘플 수만큼 반복하며 데이터를 생성\n",
    "    for i in range(n_samples):\n",
    "        # class_probs 분포에 따라 클래스 ID를 하나 샘플링\n",
    "        c = np.random.choice(list(class_names.keys()), p=class_probs)   # class_names.keys() -> [0,1,2,3,4,5,6,7,8,9]\n",
    "        \n",
    "        # 선택된 클래스의 평균 파라미터를 가져옴\n",
    "        p = params[c]\n",
    "\n",
    "        # 정규 분포를 사용하여 연속형 피처들을 생성\n",
    "        enc   = max(0, np.random.normal(p[\"enc\"],  p[\"enc\"]  * 0.3))\n",
    "        fw    = max(0, np.random.normal(p[\"fw\"],   p[\"fw\"]   * 0.3))\n",
    "        reg   = max(0, np.random.normal(p[\"reg\"],  max(5, p[\"reg\"] * 0.3)))\n",
    "        net   = max(0, np.random.normal(p[\"net\"],  max(5, p[\"net\"] * 0.3)))\n",
    "        depth = max(1, np.random.normal(p[\"depth\"], 1.0))\n",
    "        brute = max(0, np.random.normal(p[\"brute\"], max(1, p[\"brute\"] * 0.4)))\n",
    "        usb   = max(0, np.random.normal(p[\"usb\"],  max(1, p[\"usb\"]  * 0.5)))\n",
    "        cloud = max(0, np.random.normal(p[\"cloud\"],max(1, p[\"cloud\"]* 0.5)))\n",
    "\n",
    "        # 피싱/익스플로잇 여부는 Bernoulli 분포로 생성\n",
    "        ph_ind = np.random.rand() < p[\"ph\"]\n",
    "        ex_ind = np.random.rand() < p[\"ex\"]\n",
    "\n",
    "        # 한 샘플의 모든 정보를 딕셔너리에 담아 리스트에 추가\n",
    "        rows.append({\n",
    "            \"sample_id\": f\"sample_{i:05d}\",\n",
    "            \"encryption_count\": int(enc),\n",
    "            \"file_write_rate\": fw,\n",
    "            \"registry_modifications\": int(reg),\n",
    "            \"network_connections\": int(net),\n",
    "            \"process_tree_depth\": int(depth),\n",
    "            \"bruteforce_attempts\": int(brute),\n",
    "            \"usb_access_count\": int(usb),\n",
    "            \"cloud_api_access\": int(cloud),\n",
    "            \"phishing_indicator\": int(ph_ind),\n",
    "            \"exploit_indicator\": int(ex_ind),\n",
    "            \"class_id\": c,\n",
    "            \"class_name\": class_names[c],\n",
    "        })\n",
    "    # 설명: 리스트를 pandas DataFrame으로 변환하여 반환\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 위 함수로 10,000개 샘플 생성\n",
    "df = generate_synthetic_ransomware(n_samples=10000, seed=SEED)\n",
    "\n",
    "print(\" Synthetic Ransomware Dataset 생성 완료\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71742d0e",
   "metadata": {},
   "source": [
    "## EDA - 데이터 구조 및 분포 파악\n",
    "기본 통계량, 클래스 분포, 피처 상관 관계 등을 확인하여 **랜섬웨어 유형과 행위 특징의 연관성**을 시각적으로 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0f34a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# 데이터 구조 및 기본 통계 확인\n",
    "# ==========================\n",
    "\n",
    "# DataFrame의 정보\n",
    "print(\"[INFO] DataFrame info\")\n",
    "print(df.info())\n",
    "\n",
    "# 숫자형 컬럼들에 대한 기초 통계량 출력\n",
    "print(\"\\n[INFO] Numeric Describe\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5823f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================\n",
    "# 클래스 분포 시각화\n",
    "# ================\n",
    "\n",
    "# class_name 기준으로 각 랜섬웨어 유형의 개수 계산\n",
    "class_counts = df[\"class_name\"].value_counts()\n",
    "\n",
    "# 클래스 분포를 막대그래프로 그리기\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.title(\"Class Distribution (Ransomware Types)\")\n",
    "plt.xlabel(\"Ransomware Type\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 숫자 값으로 클래스 분포 확인\n",
    "print(\"\\n[INFO] Class Distribution\")\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8781e130",
   "metadata": {},
   "source": [
    "### 클래스 분포 해석\n",
    "\n",
    "- Encryptor와 Human-operated Ransom 비중이 상대적으로 높게 나타나도록 설계됨\n",
    "- USB/Cloud 기반 등의 클래스도 일정 비율을 차지해 멀티클래스 학습에 적합함\n",
    "- 실제 환경에서는 회사별 위협 프로파일에 따라 이 분포가 달라지며,\n",
    "  희귀 클래스에 대해서는 Oversampling 또는 비용 민감 학습이 필요할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196f6708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# 피처 상관관계 히트맵\n",
    "# ==================\n",
    "\n",
    "# 상관계수를 계산할 숫자형 피처 목록 정의\n",
    "numeric_cols = [\n",
    "    \"encryption_count\",\n",
    "    \"file_write_rate\",\n",
    "    \"registry_modifications\",\n",
    "    \"network_connections\",\n",
    "    \"process_tree_depth\",\n",
    "    \"bruteforce_attempts\",\n",
    "    \"usb_access_count\",\n",
    "    \"cloud_api_access\",\n",
    "    \"phishing_indicator\",\n",
    "    \"exploit_indicator\",\n",
    "]\n",
    "\n",
    "# 상관계수 행렬 계산\n",
    "corr = df[numeric_cols].corr()\n",
    "\n",
    "# 히트맵 형태로 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(corr, cmap=\"coolwarm\", interpolation=\"nearest\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.xticks(range(len(numeric_cols)), numeric_cols, rotation=45, ha=\"right\")\n",
    "plt.yticks(range(len(numeric_cols)), numeric_cols)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89277e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================\n",
    "# 클래스별 encryption_count 분포 (Boxplot)  \n",
    "#  - 파일 암호화 시도 횟수(랜섬웨어 유형을 구분하는 가장 중요한 지표)\n",
    "#    >> 랜섬웨어 유형별 주요 행동 패턴 차이 확인\n",
    "#    >> 비정상/변종 탐지의 기준값을 잡을 수 있음\n",
    "#       - Encryptor인데 encryption_count가 갑자기 낮다면 → 변종, 방해, 실패 가능성\n",
    "#       - Wiper인데 encryption_count가 너무 높으면 → 정상 패턴 벗어남(anomaly)\n",
    "# ===============================================================================\n",
    "\n",
    "# 클래스별 encryption_count 값을 리스트로 모음\n",
    "groups = []\n",
    "labels = []\n",
    "for cid, cname in class_names.items():\n",
    "    groups.append(df[df[\"class_id\"] == cid][\"encryption_count\"].values)\n",
    "    labels.append(cname)\n",
    "\n",
    "# Boxplot을 그려 클래스별 암호화 개수 분포 비교\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(groups, labels=labels, showfliers=False)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"encryption_count\")\n",
    "plt.title(\"Encryption Count Distribution by Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988bdc18",
   "metadata": {},
   "source": [
    "### Encryption Count Boxplot 해석\n",
    "\n",
    "- Encryptor, Human-operated Ransom 유형에서 encryption_count의 중앙값과 상단 사분위가 높게 나타남\n",
    "- 중앙값(Median) : 각 랜섬웨어 유형이 평균적으로 얼마나 많은 파일을 암호화하는지\n",
    "- IQR(Interquartile Range) : 암호화 수치의 변동성이 얼마나 큰지\n",
    "- 이런 패턴은 각 랜섬웨어 유형의 \"행위 시그니처\"를 파악하는 데 도움이 됨\n",
    "- Encryptor 계열(클래스 0)은 암호화 개수가 매우 높음\n",
    "- Locker(1), Wiper(2) 같은 유형은 encryption_count가 거의 없음\n",
    "- Worm-propagating, Human-operated Ransom은 보통 높은 암호화와 함께 다른 공격 요소를 수행함\n",
    "- USB 기반(8번)이나 Exploit 기반(7번)은 비교적 중간 수준임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5c561",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19176394",
   "metadata": {},
   "source": [
    "## 머신러닝 - RandomForest 기반 멀티 클래스 분류\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Feature / Target 분리 및 전처리\n",
    "# ==============================\n",
    "\n",
    "# 모델 입력 피처 리스트 정의\n",
    "feature_cols = [\n",
    "    \"encryption_count\",\n",
    "    \"file_write_rate\",\n",
    "    \"registry_modifications\",\n",
    "    \"network_connections\",\n",
    "    \"process_tree_depth\",\n",
    "    \"bruteforce_attempts\",\n",
    "    \"usb_access_count\",\n",
    "    \"cloud_api_access\",\n",
    "    \"phishing_indicator\",\n",
    "    \"exploit_indicator\"\n",
    "]\n",
    "\n",
    "\n",
    "# 입력 피처 행렬 x와 타깃 레이블 y를 정의\n",
    "X = df[feature_cols].values\n",
    "y = df[\"class_id\"].values\n",
    "\n",
    "\n",
    "# train_test_split을 이용해 데이터를 학습용과 테스트용으로 나눔\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "# 피처 스케일링을 위한 StandardScaler를 초기화\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 학습 데이터에 대해 스케일러를 학습시키고 변환\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 학습된 스케일러를 사용해 테스트 데이터도 변환\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 분리된 Train/Test 데이터의 크기 출력\n",
    "print(\"Train shape: \", X_train.shape, \"Test shape: \", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae571b24",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3254fff0",
   "metadata": {},
   "source": [
    "## LSTM 기반 랜섬웨어 유형 분류 (시퀀스 모델)\n",
    "실제 보안 로그는 시간에 따른 이벤트 시퀀스로 구성됨\n",
    "- Tabular Feature를 5 타임 스텝으로 반복한 pseudo-sequence를 만들어 LSTM 구조를 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9726a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# LSTM 입력 데이터 준비(Pseudo-Squence)\n",
    "# ===================================\n",
    "\n",
    "# 시퀀스 길이(타임스텝 수)를 5로 설정\n",
    "timesteps = 5\n",
    "\n",
    "# 학습용 데이터를 배치, 타임스텝, 피처수 형태로 변환\n",
    "X_train_seq = np.repeat(X_train_scaled[:, np.newaxis, :], timesteps, axis=1)\n",
    "\n",
    "# 테스트용 데이터도 동일한 방식으로 변환\n",
    "X_test_seq = np.repeat(X_test_scaled[:, np.newaxis, :], timesteps, axis=1)\n",
    "\n",
    "# 변환된 LSTM 입력 데이터의 형태를 출력\n",
    "print(\"LSTM Input Shape - Train: \", X_train_seq.shape)\n",
    "print(\"LSTM Input Shape - Test: \", X_test_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d3ae4",
   "metadata": {},
   "source": [
    "### ***LSTM 분류 모델 정의***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561af05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 기반 분류 모델을 생성하는 함수 정의\n",
    "def build_lstm_classifier(input_shape, num_classes:int):\n",
    "    # Sequential API를 사용해 레이어를 순차적으로 stack\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 입력 형태를 지정하는 Input 레이어\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "\n",
    "    # 시퀀스 데이터를 처리할 LSTM 레이어\n",
    "    model.add(layers.LSTM(64))\n",
    "\n",
    "    # 은닉층으로 64차원 Dense 레이어 추가\n",
    "    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "\n",
    "    # 출력 레이어로 클래스 개수 만큼 뉴런을 두고 softmax로 확률 출력\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    # 모델을 컴파일하면서 손실 함수와 최적화 알고리즘, 평가 지표 지정\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# LSTM 모델 생성\n",
    "lstm_model = build_lstm_classifier(\n",
    "    input_shape = (timesteps, X_train_scaled.shape[1]),\n",
    "    num_classes = len(class_names)\n",
    ")\n",
    "\n",
    "\n",
    "# LSTM 모델 구조 요약 정보 출력\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4634b85c",
   "metadata": {},
   "source": [
    "### ***LSTM 모델 학습 및 학습 곡선 시각화***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f51cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델을 학습 데이터에 학습\n",
    "history = lstm_model.fit(\n",
    "    X_train_seq,            # 시퀀스 형태의 학습 입력 데이터\n",
    "    y_train,                # 정답 class_id 레이블\n",
    "    epochs=5,               # 에폭 수는 데모를 위해 5로 설정\n",
    "    batch_size =64,         # 배치 크기\n",
    "    validation_split =0.2,  # 학습 데이터의 20%를 검증용으로 사용\n",
    "    verbose=1               # 학습 과정을 로그로 출력\n",
    ")\n",
    "\n",
    "\n",
    "# history 객체에 저장된 학습/검증 손실 및 정확도 곡선 가져옴\n",
    "history_dict = history.history\n",
    "\n",
    "# 두 개의 서브플롯(손실, 정확도)을 그리기 위해 그림 크기 설정\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# 첫 번째 서브 프롨에 학습/검증 \"손실\" 곡선 그리기\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_dict[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history_dict[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"LSTM Training/Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# 두 번ㅌ째 서브 플롯에 학습/검증 \"정확도\" 곡선 그리기\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_dict[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history_dict[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"LSTM Training/Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# 두 서브 플롯 사이의 레이아웃을 자동 조정\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 학습이 완료된 LSTM 모델을 테스트 세트에서 평가\n",
    "loss_lstm, acc_lstm = lstm_model.evaluate(X_test_seq, y_test, verbose=0)\n",
    "\n",
    "print(f\"[LSTM] Test Loss: {loss_lstm:.4f}, Test Accuracy: {acc_lstm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5e8215",
   "metadata": {},
   "source": [
    "### LSTM 학습 해석\n",
    "\n",
    "- Loss 곡선이 안정적으로 감소하고, Train/Validation 간 큰 차이가 없으면 과적합이 심하지 않다고 볼 수 있습니다.\n",
    "- Accuracy 곡선이 일정 수준 이상에서 수렴하면 모델이 데이터의 패턴을 어느 정도 학습한 것으로 해석할 수 있습니다.\n",
    "- 실제 환경에서 시퀀스 로그(시간 순서 이벤트)를 입력으로 사용하면 LSTM/Transformer의 장점을 더 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7731ac79",
   "metadata": {},
   "source": [
    "### ***LSTM 단일 샘플 예측 예시***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ec4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 세트에서 첫 번째 시퀀스 샘플 선택\n",
    "sample_idx = 2\n",
    "\n",
    "# 선택한 샘플을 LSTM 모델에 입력하여 클래스별 확률 예측\n",
    "lstm_probs = lstm_model.predict(X_test_seq[sample_idx:sample_idx+1])\n",
    "\n",
    "# 가장 높은 확률을 가진 인덱스를 예측 클래스 ID로 선택\n",
    "lstm_pred_class = int(np.argmax(lstm_probs))\n",
    "\n",
    "# 실제 정답과 예측 결과 출력\n",
    "print(\"=== LSTM 단일 샘플 예측 예시 ===\")\n",
    "print(\"Sample Index: \", sample_idx)\n",
    "print(\"True Class  : \", class_names[y_test[sample_idx]])\n",
    "print(\"Predicted Class: \", class_names[lstm_pred_class])\n",
    "\n",
    "# 각 클래스에 대한 예측 확률 분포도 함께 출력\n",
    "print(\"Class probabilities: \", [f\"{p:.10f}\" for p in lstm_probs[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5c6ca9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d2536",
   "metadata": {},
   "source": [
    "## Autoencoder 기반 Encryptor 이상 탐지\n",
    "Encryptor(class_id==0)를 \"정상 패턴\"으로 간주하고 Autoencoder로 해당 패턴을 학습 이후 재구성 오차(MSE)를 활용해 이상 여부를 판단하는 이상탐지 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a12e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
