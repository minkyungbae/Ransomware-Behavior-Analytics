import numpy as np
import pandas as pd
import tensorflow as tf
import json
import os

from tensorflow.keras.models import Model, save_model
from tensorflow.keras.layers import Input, Dense, LSTM
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# ----------------------------------------------------
# ğŸ“Œ íŒŒì¼ ê²½ë¡œ ì •ì˜
# ì´ ê²½ë¡œëŠ” TrainML.pyì— ì •ì˜ëœ ê²½ë¡œì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
# ----------------------------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATASET_PATH = os.path.join(BASE_DIR, "ransomwaredataset.csv") # ë°ì´í„°ì…‹ ê²½ë¡œ
AE_MODEL_PATH = os.path.join(BASE_DIR, "autoencoder_model.h5")
LSTM_MODEL_PATH = os.path.join(BASE_DIR, "lstm_model.h5")
AE_THRESHOLD_PATH = os.path.join(BASE_DIR, "ae_threshold.json")


# ====================================================
# A. ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ì˜ (notebook ê¸°ë°˜ìœ¼ë¡œ ë‹¨ìˆœí™”)
# ====================================================

def build_autoencoder(input_dim):
    """Autoencoder ëª¨ë¸ ì •ì˜"""
    input_layer = Input(shape=(input_dim,))
    # ì¸ì½”ë”
    encoded = Dense(64, activation='relu')(input_layer)
    encoded = Dense(32, activation='relu')(encoded)
    # ë””ì½”ë”
    decoded = Dense(32, activation='relu')(encoded)
    decoded = Dense(64, activation='relu')(decoded)
    output_layer = Dense(input_dim, activation='sigmoid')(decoded) # ì…ë ¥ê³¼ ê°™ì€ ì°¨ì›
    
    model = Model(inputs=input_layer, outputs=output_layer)
    model.compile(optimizer='adam', loss='mse')
    return model

def build_lstm(input_shape):
    """LSTM ëª¨ë¸ ì •ì˜ (ì´ì§„ ë¶„ë¥˜)"""
    model = tf.keras.Sequential([
        LSTM(units=64, input_shape=input_shape),
        Dense(32, activation='relu'),
        Dense(10, activation='softmax') 
    ])
    # Autoencoderì˜ ì¬êµ¬ì„± ì˜¤ì°¨ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì¼ë°˜ì ì¸ ì´ì§„ ë¶„ë¥˜ ì§€í‘œ ì‚¬ìš©
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model


# ====================================================
# B. ì„ê³„ê°’ ê³„ì‚° ë° ì €ì¥ ë¡œì§
# ====================================================

def calculate_and_save_threshold(ae_model, X_normal_data):
    """
    í›ˆë ¨ëœ Autoencoderë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ìƒ ë°ì´í„°ì˜ ì¬êµ¬ì„± ì˜¤ì°¨ë¥¼ ê³„ì‚°í•˜ê³  ì„ê³„ê°’ì„ ì €ì¥
    """
    print("\n[3] Autoencoder ì„ê³„ê°’ ê³„ì‚° ë° ì €ì¥ ì¤‘...")
    
    # 1. ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚°
    X_reconstructed = ae_model.predict(X_normal_data, verbose=0)
    reconstruction_errors = np.mean(np.square(X_normal_data - X_reconstructed), axis=1)

    # 2. ì„ê³„ê°’ ê²°ì • (ì¼ë°˜ì ì¸ ë°©ë²•: í‰ê·  + 2 * í‘œì¤€í¸ì°¨)
    mean_err = np.mean(reconstruction_errors)
    std_err = np.std(reconstruction_errors)
    # ë³´í†µ 2~3 í‘œì¤€í¸ì°¨ë¥¼ ì‚¬ìš©í•˜ë©°, ì—¬ê¸°ì„œëŠ” 2ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    THRESHOLD = mean_err + (2 * std_err) 
    
    # 3. ì„ê³„ê°’ì„ JSON íŒŒì¼ë¡œ ì €ì¥
    try:
        with open(AE_THRESHOLD_PATH, 'w') as f:
            json.dump({"threshold": float(THRESHOLD)}, f)
        print(f"âœ… ì„ê³„ê°’ {THRESHOLD:.6f}ê°€ '{os.path.basename(AE_THRESHOLD_PATH)}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return THRESHOLD
    except Exception as e:
        print(f"âš ï¸ ì„ê³„ê°’ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

# ====================================================
# C. ë©”ì¸ í›ˆë ¨ ë£¨í‹´
# ====================================================

def initial_train_and_save():
    print(f"ë°ì´í„°ì…‹ ë¡œë“œ: {DATASET_PATH}")
    
    try:
        df = pd.read_csv(DATASET_PATH)
    except FileNotFoundError:
        print(f"ğŸš¨ ì˜¤ë¥˜: {DATASET_PATH} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤.")
        return

    # 1. ë°ì´í„°ì…‹ ë¶„ë¦¬ ë° ì „ì²˜ë¦¬
    # íŠ¹ì§•(X)ê³¼ ë ˆì´ë¸”(Y) ë¶„ë¦¬. 'class_name'ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ.
    feature_cols = df.columns.drop(['sample_id', 'class_id', 'class_name']).tolist()
    X = df[feature_cols].values
    Y = df['class_id'].values # YëŠ” class_id (0:ì •ìƒ, 1~n:ì•…ì„±)

    # ìŠ¤ì¼€ì¼ë§
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)
    input_dim = X_scaled.shape[1]
    
    # 2. Autoencoder í›ˆë ¨ (ì •ìƒ ë°ì´í„°ë§Œ ì‚¬ìš©)
    # âš ï¸ ì¤‘ìš”: AutoencoderëŠ” ì •ìƒ ë°ì´í„°(class_id=0)ë§Œ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨í•´ì•¼ í•©ë‹ˆë‹¤.
    # CSV íŒŒì¼ ìŠ¤ë‹ˆí«ì—ëŠ” class_id=0ì´ ë³´ì´ì§€ ì•Šìœ¼ë¯€ë¡œ, ë°ì´í„°ì…‹ì— ì •ìƒ ìƒ˜í”Œì´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
    print("\n[1] Autoencoder í›ˆë ¨ (ì •ìƒ ë°ì´í„°ë§Œ ì‚¬ìš©) ì‹œì‘...")
    X_normal = X_scaled[Y == 0]
    
    if X_normal.shape[0] == 0:
        print("âŒ ê²½ê³ : ì •ìƒ ë°ì´í„°(class_id=0)ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤ (ê¶Œì¥ë˜ì§€ ì•ŠìŒ).")
        X_ae_train = X_scaled
    else:
        X_ae_train = X_normal
        
    X_ae_train, X_ae_val = train_test_split(X_ae_train, test_size=0.2, random_state=42)
    
    ae_model = build_autoencoder(input_dim)
    ae_model.fit(X_ae_train, X_ae_train, epochs=50, batch_size=32, validation_data=(X_ae_val, X_ae_val), verbose=1)
    
    # 3. ì„ê³„ê°’ ê³„ì‚° ë° ì €ì¥ (Autoencoder í›ˆë ¨ ì§í›„)
    calculate_and_save_threshold(ae_model, X_ae_train)
    save_model(ae_model, AE_MODEL_PATH)
    print(f"âœ… Autoencoder ëª¨ë¸ì´ '{os.path.basename(AE_MODEL_PATH)}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


    # 4. LSTM í›ˆë ¨ (ì „ì²´ ë°ì´í„° ì‚¬ìš©)
    print("\n[4] LSTM í›ˆë ¨ (ì „ì²´ ë°ì´í„° ì‚¬ìš©) ì‹œì‘...")
    # LSTM ì…ë ¥ reshape: (ìƒ˜í”Œ ìˆ˜, 1, í”¼ì²˜ ìˆ˜)
    X_lstm = X_scaled.reshape((X_scaled.shape[0], 1, input_dim)) 
    
    # ì´ì§„ ë¶„ë¥˜ë¥¼ ìœ„í•´ ë ˆì´ë¸”ì„ 0 ë˜ëŠ” 1ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
    # class_idê°€ 0(ì •ìƒ)ì´ë©´ 0, ê·¸ ì™¸(1~n)ëŠ” 1(ì•…ì„±)ë¡œ ë³€í™˜ (í•„ìš”ì‹œ)
    Y_binary = np.where(Y > 0, 1, Y) 
    
    lstm_model = build_lstm((1, input_dim))
    lstm_model.fit(X_lstm, Y_binary, epochs=20, batch_size=32, validation_split=0.2, verbose=1)
    
    # 5. LSTM ëª¨ë¸ ì €ì¥
    save_model(lstm_model, LSTM_MODEL_PATH)
    print(f"âœ… LSTM ëª¨ë¸ì´ '{os.path.basename(LSTM_MODEL_PATH)}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    initial_train_and_save()